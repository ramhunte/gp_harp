---
title: "Future flow changes"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```



# Change in peak flow

This section holds the code used to calculate the changes in peak flow under future conditions. Here we take the results from the [CIG study](https://cig.uw.edu/news-and-events/datasets/hydrology-in-the-chehalis-basin/) and create regressions used to translate recurrence interval into percent change to annual peak flow.

## Load and prep data

The first step is to load all of the data, and convert it into a usable format. We load the data from all bias corrected sites and put variable names into separate columns. 

```{r}
cig_dat <- list.files('../../../misc/AGU_poster/CIG_model_results/streamflow_summaries/summaries_BCsites/',
           pattern = 'ALL_BCsites.*Flood',
           full.names = TRUE) %>%
  map_dfr(., function(x) {
    
    y <- x %>% 
      read.csv %>%
      mutate(file = basename(x))
    
    y[y == "--"] <- NA
    
    return(y)
  }) %>%
  mutate(era = str_extract(file, "\\d{4}"),
         ri = str_extract(file, "\\d+\\b(?=\\-yr)")) %>%
  gather(col_name, value, RAW.WRF.DHSVM.min....:MACA_RCP_8.5.VIC.max....) %>%
  mutate(hydro_model = str_extract(col_name, "DHSVM|VIC"),
         climate_model = str_extract(col_name, "4.5|8.5"),
         metric = str_extract(col_name, 'min|max|avg'),
         ri = factor(ri, levels = c('2', '10', '50', '100', '500')))

head(as_tibble(cig_dat))
```
Next we subset to only the 'average' data points for the Grand Mound site at flows less than 500 year RI. For example data from the column `MACA_RCP_4.5-VIC-avg (%)` would be included here, but *not* data from the column `MACA_RCP_4.5-VIC-min (%)`.

```{r}
cig_ave <- cig_dat %>%
  mutate(ri = as.numeric(as.character(ri)),
         value = value / 100) %>%
  filter(metric == 'avg',
         #site.name == 'ChehalisR-nrGrandMound',
         site.name == 'ChehalisR-atPorter',
         ri < 500
         )
```


## Create regression models

Next we create the regression models for each of the four future scenarios

1. RCP 4.5 - 2040
2. RCP 4.5 - 2080
3. RCP 8.5 - 2040
4. RCP 8.5 - 2080

Regressions are created using log transformed recurrence interval, and include an intercept

$$\Delta Q = \beta_0 + ln(RI)$$

```{r}
mods <- cig_ave %>%
  group_by(climate_model, era) %>%
  nest %>%
  mutate(fit = map(data, ~ lm(value ~ log(ri), data = .x)))
```

Models are now created and ready to be used. 

## Visualize it

In order to visualize what we have done, we will plot the modeled CIG data with the regressions overlain. First we will create some predicted data using the regressions.

```{r}
mods_pred <- data.frame(ri = 1:max(cig_ave$ri)) %>%
  mutate(diff_perc_rcp4.5_2050 = predict(mods$fit[[1]], newdata = .),
         diff_perc_rcp4.5_2080 = predict(mods$fit[[2]], newdata = .),
         diff_perc_rcp8.5_2050 = predict(mods$fit[[3]], newdata = .),
         diff_perc_rcp8.5_2080 = predict(mods$fit[[4]], newdata = .)) %>%
  gather(model, value, diff_perc_rcp4.5_2050:diff_perc_rcp8.5_2080) %>%
  mutate(climate_model = str_extract(model, "4.5|8.5"),
         era = str_extract(model, "2050|2080")) %>%
  mutate(climate_model = ifelse(climate_model == 4.5, 'RCP 4.5', 'RCP 8.5'))
```

Then we plot it! 

```{r fig.height=4, fig.width=7}
p5 <- cig_ave %>%
  mutate(climate_model = ifelse(climate_model == 4.5, 'RCP 4.5', 'RCP 8.5')) %>%
  group_by(ri, era, climate_model) %>%
  summarize(value = mean(value)) %>%
  ggplot +
  theme_bw() +
  theme(panel.grid = element_blank()) +
  geom_point(aes(ri, 
                 value#, 
                 #shape = hydro_model
                 ),
             size = 2) +
  geom_line(data = mods_pred, 
            aes(ri, value)) +    
  facet_grid(era~climate_model) +
  scale_y_continuous(labels = scales::percent) +
  labs(x = 'Recurrence interval (years)',
       y = 'Change from current',
       #shape = 'Hydrologic model',
       color = 'Site')
       #title = cig_ave$site.name[1])

ggsave('Fig5_peak_flow_change.tiff', p5, height = 3, width = 5, dpi = 300, compression = 'lzw')
```

## Calculate a couple of summary metrics

Average change

```{r}
cig_ave %>%
  group_by(era, climate_model) %>%
  summarize(mean_change = mean(value))

```

```{r}
mods %>%
  mutate(tidy = map(fit, broom::tidy)) %>%
  unnest(cols = c(tidy)) %>%
  select(era, climate_model, term, estimate) %>%
  spread(term, estimate)
```


# Recurrence intervals

## Log-Pearson Type III

To create recurrence intervals, we use a log-pearson type III distribution. The inputs to a USGS function from the `swmrBase` package are mean, standard deviation and skewness of the peak flow data. 

See the swmrBase github page for directions on how to install: https://github.com/USGS-R/smwrBase#package-installation. The following code must be run and R restarted before the package can be installed.

NOTE: Should we choose skew from here? http://www.dimensionengine.com/excel/hydrotools/functions/logpearson.html

The package `moments` is needed for the `skewness()` function. 
```{r, eval= FALSE}
rprofile_path = file.path(Sys.getenv("HOME"), ".Rprofile")
write('\noptions(repos=c(getOption(\'repos\'),
  CRAN=\'https://cloud.r-project.org\',
  USGS=\'https://owi.usgs.gov/R\'))\n',
    rprofile_path, 
    append =  TRUE)

cat('Your Rprofile has been updated to include GRAN.
  Please restart R for changes to take effect.')
```


```{r}
library(smwrBase)
#library(moments)

# ri_to_q <- function(ri, q_record, sk) {
#   # ri = vector of one or more recurrance intervals, eg. c(2, 10, 100)
#   # q_record = vector of peak annual flows
#   
#   non_exeed_prob <- 1 - (1/ri)
#   
#   q_log <- log10(q_record)
#   
#   mn_log <- mean(q_log)
#   sd_log <- sd(q_log)
#   sk_log <- sk#0.12#skewness(log10(q_record))
#   
#   lp3 <- qpearsonIII(p = non_exeed_prob,
#                      mean =  mn_log,
#                      sd =  sd_log,
#                      skew = sk_log)
#   
#   return(10^lp3)
#   
# }
```

We also need to be able to translate flow to recurrance intervals.

```{r}
# q_to_ri <- function(q, q_record, sk) {
#   
#   q_log <- log10(q_record)
#   
#   mn_log <- mean(q_log)
#   sd_log <- sd(q_log)
#   sk_log <- sk#skewness(log10(q_record))
#   
#   exeed_prob <- ppearsonIII(q = log10(q),
#                             mean =  mn_log,
#                             sd =  sd_log,
#                             skew = sk_log)
#   
#   ri <- 1 / (1 - exeed_prob)
#     
#   return(ri)
# 
# }
```


## Skagit

The recurrence intervals for the skagit are needed to reanalyze the data in (Kinsel 2006)[https://wdfw.wa.gov/publications/00092].

The data are from USGS gage #12200500, Skagit River Near Mt. Vernon.

```{r}
library(EGRET)

# # Load Skagit data
# peak_mv <- readNWISDaily(12200500,'00060') %>%
#  # filter(between(waterYear, 1970, 1999)) %>%
#   group_by(waterYear) %>%
#   summarize(q_cfs = max(Q) * 35.31467)
```

```{r}
# # Calculate the 2, 10, 50 and 100 year floods
# data.frame(ris = c(2, 10, 50, 100)) %>%
#   mutate(Q = ri_to_q(ris, peak_mv$q_cfs, 0.12))

```

Here we set up the Skagit data used to make the regression between survival and recurrence interval. Q and survival data from Zimmerman 2015.

```{r}


zimmerman <- read.csv('Zimmerman_2015.csv')


dat_z <- zimmerman %>%
  select(year:Peak) %>%
  mutate(surv = (Fry + Parr + Yearlings)/(PED*1e6)) %>%
  rename(ri = Peak)

#ri_to_surv <- lm(log(surv/(1-surv)) ~ ri, data = dat_z)
#ri_to_surv <- lm(surv ~ log(ri), data = dat_z)
ri_to_surv <- nls(log(surv) ~ a*ri^b, data = dat_z, start = list(a = 1, b = 0))

summary(ri_to_surv)
```


### Create the regression between flow and survival

We logit transform the survival data then fit a regression with recurrence interval. 

```{r}

#ri_to_surv <- lm(log(surv/(1-surv)) ~ ri, data = dat_z)
#ri_to_surv <- lm(surv ~ log(ri), data = dat_sk)
ri_to_surv <- nls(log(surv) ~ a*ri^b, data = dat_z, start = list(a = 1, b = 0))

summary(ri_to_surv)
```

In order to make predictions of survival, we need to use the regression to make a prediction then inverse the logit transform. 

```{r}
# Inverse logit function
ri.to.surv <- function(ri){
  
  x <- data.frame(ri = ri) %>%
    mutate(surv_pred = predict(ri_to_surv, newdata = .),
           surv_pred = surv_pred %>% exp)
  
  return(x$surv_pred)
  
  #y <- exp(x)/(exp(x) + 1)
  
  
  
  #y <- exp(x)
  #return(y)
  
  #return(x)
}

ri.to.surv(1:100)

sk_pred <- data.frame(ri = 1:100) %>%
  mutate(surv_pred = ri.to.surv(ri))
  #mutate(surv_pred = 0.1747 * ri^-0.573)
  #mutate(surv_pred = 0.1715 * ri^-0.488)
```





```{r}
p3 <- ggplot() +
  cowplot::theme_half_open() +
  geom_point(data = dat_z, aes(ri, surv)) +
  #stat_smooth(method = 'nls', formula = 'surv~a*ri^b')
  geom_line(data = sk_pred, aes(ri, surv_pred)) +
  scale_x_log10() +
  scale_y_continuous(labels = scales::label_percent(accuracy = 1L),
                     limits = c(0, .25)) +
  #geom_vline(xintercept = 1.5, lty = 2) +
  labs(x = 'Recurrence interval (years)',
       y = 'Egg to migrant survival') +
  annotation_logticks(sides = 'b')

ggsave('Fig3_ri_vs_survival.tiff',p3, height = 3, width = 5, dpi = 300, compression = 'lzw')

p3
  
```


Compare Jeff's function to this new one

```{r}
data.frame(ri = 1:100) %>%
  mutate(j_pred = -1.88084588 +  -0.05511075 * ri,
         original = exp(j_pred)/(exp(j_pred) + 1),
         redo = ri.to.surv(ri)) %>%
  select(-j_pred) %>%
  gather(model,surv, original:redo) %>%
  ggplot +
  theme_classic() +
  geom_line(aes(ri, surv, color = model))
```


#### Rescale the function

```{r}
range.rescale <- function(x, 
                          min = ri.to.surv(100),
                          max = ri.to.surv(1)) 
{
  y <- (x - min) / (max - min)
  return(y)
}

# range.rescale <- function(c,
#                           y = ri.to.surv(100),
#                           z = 1)
# {
#   (c - ri.to.surv(100)) * (z - y) / (ri.to.surv(1) - ri.to.surv(100)) + y
# }
# 
range.rescale(ri.to.surv(1:100))
```


```{r}
ggplot() +
  theme_classic() +
  geom_point(data = dat_z %>% 
               mutate(surv_rescale = range.rescale(surv)), 
             aes(ri, surv_rescale)) +
  geom_line(data = sk_pred %>%
              mutate(surv_pred_rescale = range.rescale(surv_pred)), 
                     aes(ri, surv_pred_rescale)) +
  scale_x_log10(limits=c(1, 100)) +
  geom_vline(xintercept = 1.5, lty = 2)

```


```{r}
dat_z %>% 
  mutate(surv_rescale = range.rescale(surv) %>% round(2), 
         ri = ri %>% round(1)) %>%
  rename(Year = year, RI = ri, p = surv,  p_rescale = surv_rescale) %>%
  select(Year, RI, p, p_rescale) %>%
  flextable::flextable()
```


Bring it all together in one function to turn RI into a survival scalar

```{r}
ri_to_surv_rescale <- function(ri) {
  
  surv_rescale <- ri.to.surv(ri) %>%
    range.rescale()
  
  # If survival is negative, make zero
  surv_rescale[surv_rescale < 0] <- 0
  
  
  return(surv_rescale)
}

ri_to_surv_rescale(c(1, 2, 10, 50, 100))
```


# Chehalis at Porter

The lowest gage in the mainstem is Chehalis at Porter. We use this one to calculate a time series of recurrence intervals and survivals.

```{r}
library(EGRET)

# Load Chehalis data
daily_ch <- readNWISDaily(12031000,'00060') %>% # Porter gage
 filter(waterYear %in% 1970:1999)
#        waterYear != 1975)

#daily_ch <- readNWISDaily(12027500,'00060') # Grand Mound gage


q_to_ri <- function(q_cfs){
  
  # Values from Chehalis_at_Port_1970_1999.EXP
  lp3_stat <- ppearsonIII(q = log10(q_cfs),
                          mean =  4.496,
                          sd =  0.188,
                          skew = 0.025)
  
  return(1 / (1 - lp3_stat))
}

```

```{r}
# Setup function to generate 100 year time series from 30 years of data

loop_series <- function(ts, start_point = 20, years = 100){ 
  # Input an arbitrary time series/vector
  # Choose a random starting point
  # Repeat series up to length(years)
  
  ts_len <- length(ts)
  
  ts_start <- ts[start_point:ts_len]

  mult <- ((years - length(ts_start))/ts_len) + 1
  
  ts_rep <- rep(ts, mult)
  
  ts_years <- c(ts_start, ts_rep)[1:years]
  
  return(ts_years)
  
}

#random_start(1:30, 100)
```


```{r}

# coho Nov 15 - May 15 (320-136) 181 days
# spring Sep 1 - April 15 (245-106) 226 days
# fall Oct 1 - May 1 (275-122) 216 days
# sthd feb 15 - Sep 15 (46-259) 152 days

start_day <- 220# 275 = Oct 1, 213 = August 1

p7 <- daily_ch %>%
  mutate(day_plot = ifelse(Day >= start_day, Day - start_day, Day + 365 - start_day)) %>%
  ggplot(aes(day_plot, Q)) +
  geom_point() +
  scale_x_continuous(
    breaks = seq(0,364, length.out = 13)[-13],
    labels = 
      function(x) format(as.Date(as.character(ifelse(x <= (365 - start_day), x + start_day, x - (365 - start_day))), "%j"), "%b"),
    expand = expand_scale(mult = c(0, 0))
    ) +
  labs(x = NULL, 
       y = bquote('Discharge'~(m^3* s^-1))) +
  cowplot::theme_half_open() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0)) +
  scale_y_continuous(expand = expand_scale(mult = c(0, 0)),
                     limits = c(0,2000)) +
  geom_rect(xmin = 100, xmax = 281, ymin = 1900, ymax = 2000, fill = "grey55") +
  annotate(geom = 'text', x = mean(c(100, 281)), y = mean(c(1900, 2000)), label = 'Coho') +
  geom_rect(xmin = 25, xmax = 250, ymin = 1800, ymax = 1900, fill = "grey65") +
  annotate(geom = 'text', x = mean(c(25, 250)), y = mean(c(1800, 1900)), label = 'Spring Chinook') +
  geom_rect(xmin = 55, xmax = 271, ymin = 1700, ymax = 1800, fill = "grey75") +
  annotate(geom = 'text', x = mean(c(55, 271)), y = mean(c(1700, 1800)), label = 'Fall Chinook') +
  geom_rect(xmin = 0, xmax = 39, ymin = 1600, ymax = 1700, fill = "grey85") +
  geom_rect(xmin = 191, xmax = 365, ymin = 1600, ymax = 1700, fill = "grey85") +
  annotate(geom = 'text', x = 250, y = mean(c(1600, 1700)), label = 'Steelhead')


ggsave('Fig7_incubation_timing.tiff', p7, height = 4, width = 6, dpi = 300, compression = 'lzw')

p7
```


``` {r}
# peak_ch_peakfq <- 'PEAKFQ_CHEHALIS_AT_PORTER_1970_1999.EXP' %>%
#   read.delim(skip = 7,
#              header = TRUE) %>%
#   mutate(ri = 1/EMAEst) %>%
#   rename(waterYear = WaterYr) %>%
#   select(waterYear, RankedQ, ri)
# 
# peak_ch <- daily_ch %>%
#   group_by(waterYear) %>%
#   summarize(q_cfs = max(Q) * 35.31467) %>%
#   left_join(peak_ch_peakfq)
# 
# peak_ch$ri[peak_ch$waterYear == 1986] <- peak_ch$ri[peak_ch$waterYear == 1987]

 # surv_df <- daily_ch %>%
 #    mutate(month = month(Date)) %>%
 #    filter(month %in% incubation_months[[which(pop == pops)]]) %>%
 #    group_by(waterYear) %>%
 #    summarize(Q_max = max(Q))
 # 
 # surv_df$waterYear == peak_ch$waterYear
```

```{r}

# data.frame(ri = c(2, 10, 50, 100, 500),
#            q_cig = c(28584, 44790, 58377, 63952, 76464)) %>%
#   mutate(q_lp3 = ri_to_q(ri, peak_ch$q_cfs, 0.14)) %>%
#   gather(model, q, q_cig:q_lp3) %>%
#   ggplot +
#   geom_point(aes(ri, q, color = model))

```


```{r}

# ri_ch <- peak_ch %>%
#   mutate(ri = q_to_ri(q_cfs, q_cfs, 0.14),
#          surv_rescale = ri_to_surv_rescale(ri))
# 
# ri_ch %>%
#   gather(param, value, q_cfs:surv_rescale) %>%
#   ggplot() +
#   geom_line(aes(waterYear, value)) +
#   facet_wrap(~param, ncol = 1, scales = 'free_y')
```

```{r}
# 
# 
# zimmerman <- read.csv('Zimmerman_2015.csv')
# 
# 
# dat_z <- zimmerman %>%
#   select(year:Peak) %>%
#   mutate(surv = (Fry + Parr + Yearlings)/(PED*1e6)) %>%
#   rename(ri = Peak)# %>%
#   # left_join(dat_sk_peakfq) %>%
#   # mutate(ri = ri %>% round(0))
# 
# #ri_to_surv <- lm(log(surv/(1-surv)) ~ ri, data = dat_z)
# #ri_to_surv <- lm(surv ~ log(ri), data = dat_z)
# ri_to_surv <- nls(log(surv) ~ a*ri^b, data = dat_z, start = list(a = 1, b = 0))
# 
# summary(ri_to_surv)
# 
# # Inverse logit function
# inv.logit <- function(x){
#   #y <- exp(x)/(exp(x) + 1)
#   
#   y <- exp(x)
#   return(y)
#   
#   #return(x)
# }
# 
# sk_pred <- data.frame(ri = 1:100) %>%
#   mutate(surv_pred = predict(ri_to_surv, newdata = .) %>% inv.logit())
#   #mutate(surv_pred2 = (-1.86901 * ri^0.10797) %>% exp)
#   #mutate(surv_pred = 0.1715 * ri^-0.488)
# 
# 
# ggplot() +
#   theme_bw() +
#   geom_point(data = dat_z, aes(ri, surv)) +
#   #stat_smooth(method = 'nls', formula = 'surv~a*ri^b')
#   geom_line(data = sk_pred, aes(ri, surv_pred)) +
#   scale_x_log10() +
#   scale_y_continuous(labels = scales::percent) +
#   geom_vline(xintercept = 1.5, lty = 2) +
#   labs(x = 'Recurrence interval (years)',
#        y = 'Egg to migrant survival') +
#   annotation_logticks(sides = 'b')


```

